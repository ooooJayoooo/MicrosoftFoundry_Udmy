{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7aa3b22",
   "metadata": {},
   "source": [
    "## Working with Memories to Store User Context Across Sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc44149c",
   "metadata": {},
   "source": [
    "### Installing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf14aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-ai-projects==2.0.0b2 openai==1.109.1 python-dotenv azure-identity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e73d04e",
   "metadata": {},
   "source": [
    "### Setting up the Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2817cb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "load_dotenv()\n",
    "\n",
    "foundry_project_endpoint = os.getenv(\"FOUNDRY_PROJECT_ENDPOINT\")\n",
    "model_deployment_name = os.getenv(\"MODEL_DEPLOYMENT_NAME\")\n",
    "embedding_model_name = os.getenv(\"TEXT_EMBEDDING_MODEL_NAME\")\n",
    "\n",
    "\n",
    "print(\"embedding_model_name:\", embedding_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f86535",
   "metadata": {},
   "source": [
    "### Creating the Foundry Project Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c9c9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AIProjectClient(\n",
    "    endpoint=foundry_project_endpoint,\n",
    "    credential=DefaultAzureCredential()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780f016b",
   "metadata": {},
   "source": [
    "### Defining the Memory Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eee9ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects.models import MemoryStoreDefaultDefinition, MemoryStoreDefaultOptions\n",
    "\n",
    "# Define the Memory Store\n",
    "definition = MemoryStoreDefaultDefinition(\n",
    "    chat_model = model_deployment_name,\n",
    "    embedding_model=embedding_model_name,\n",
    "    options = MemoryStoreDefaultOptions(\n",
    "        user_profile_enabled=True,\n",
    "        chat_summary_enabled=True\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create the Memory Store\n",
    "memory_store = client.memory_stores.create(\n",
    "    name = \"demo_memory_store_v1\",\n",
    "    definition = definition,\n",
    "    description = \"A memory store to retain user context across sessions\"\n",
    ")\n",
    "\n",
    "print(\"Memory Store created with name:\", memory_store.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7584373f",
   "metadata": {},
   "source": [
    "### Creating a Function to Update the Memory Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676b1682",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects.models import ResponsesUserMessageItemParam\n",
    "\n",
    "def update_memory_store(memory_store_name: str, user_name: str, user_message: str):\n",
    "    try:\n",
    "        \n",
    "        # set the scope to associate the memories with\n",
    "        scope = user_name\n",
    "\n",
    "        user_message_item = ResponsesUserMessageItemParam(\n",
    "            content = user_message\n",
    "        )\n",
    "\n",
    "        update_poller = client.memory_stores.begin_update_memories(\n",
    "            name = memory_store_name,\n",
    "            scope = scope,\n",
    "            items = [user_message_item],\n",
    "            update_delay=0\n",
    "        )\n",
    "\n",
    "        # Wait for the update operation to complete\n",
    "        update_result = update_poller.result()\n",
    "\n",
    "        print(f\"Updated with {len(update_result.memory_operations)} memory operations\")\n",
    "\n",
    "        for operation in update_result.memory_operations:\n",
    "            print(\n",
    "                f\"  - Operation: {operation.kind}, Memory ID: {operation.memory_item.memory_id}, Content: {operation.memory_item.content}\"\n",
    "        )\n",
    "        \n",
    "        return \"updated successfully\"\n",
    "    except Exception as e:\n",
    "        print(\"Error updating memory store:\", str(e))\n",
    "        return \"update failed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12856e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_memory_store(\n",
    "    memory_store_name = memory_store.name,\n",
    "    user_name = \"kuljot\",\n",
    "    user_message = \"My name is Kuljot Singh and I love programming in Python. I am also allergic to peanuts and dairy.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c00c3d",
   "metadata": {},
   "source": [
    "### Creating the Agent in Foundry Agent Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d41d9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects.models import PromptAgentDefinition\n",
    "\n",
    "agent_name = \"helpful-assistant-agent\"\n",
    "\n",
    "agent = client.agents.create_version(\n",
    "    agent_name=agent_name,\n",
    "    definition=PromptAgentDefinition(\n",
    "        model=model_deployment_name,\n",
    "        instructions=\"You are a helpful assistant. Respond to all queries in a friendly and informative manner.\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "# printing the agent id\n",
    "print(f\"Agent created (id: {agent.id}, name: {agent.name}, version: {agent.version})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9206a4df",
   "metadata": {},
   "source": [
    "### Creating a Chat System to See the Memories in Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccedb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects.models import MemorySearchOptions\n",
    "\n",
    "chat = True\n",
    "\n",
    "user_name = input(\"Enter the user name (or type 'exit' to quit): \")\n",
    "\n",
    "while chat:\n",
    "    user_message = input(\"Type \\\"exit\\\" to quit the chat, \\\"update\\\" to update memory store with agent response. or ask your question.\")\n",
    "\n",
    "    if user_message.lower() == 'exit':\n",
    "        chat = False\n",
    "    # Only update memory store if user entered \"UPDATE\"\n",
    "    if user_message.strip().upper() == \"UPDATE\":\n",
    "            user_query = input(\"Enter something that you want to add to the memory store:\")\n",
    "            update_memory_store(\n",
    "                memory_store_name = memory_store.name,\n",
    "                user_name = user_name,\n",
    "                user_message = user_query\n",
    "            )\n",
    "    else:\n",
    "        # creating the openai client\n",
    "        openai_client = client.get_openai_client()\n",
    "\n",
    "        # searching for memories and appending to the user message as grounding context\n",
    "        query_message = ResponsesUserMessageItemParam(content = user_message)\n",
    "\n",
    "        search_response = client.memory_stores.search_memories(\n",
    "            name = memory_store.name,\n",
    "            scope = user_name,\n",
    "            items = [query_message],\n",
    "            options = MemorySearchOptions(max_memories=5)\n",
    "        )\n",
    "        \n",
    "        # appending the found memories to the user message to create grounding context\n",
    "        if len(search_response.memories) > 0:\n",
    "            for memory in search_response.memories:\n",
    "                print(f\"Found Memory: {memory.memory_item.content}\")\n",
    "                user_message += f\"\\nMemory Context: {memory.memory_item.content}\"\n",
    "\n",
    "        response = openai_client.responses.create(\n",
    "            extra_body = {\n",
    "                \"agent\": {\n",
    "                    \"name\": agent_name,\n",
    "                    \"type\": \"agent_reference\"\n",
    "                }\n",
    "            },\n",
    "            input = user_message\n",
    "        )\n",
    "\n",
    "        agent_response = response.output_text\n",
    "\n",
    "        print(f\"Agent: {agent_response}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
